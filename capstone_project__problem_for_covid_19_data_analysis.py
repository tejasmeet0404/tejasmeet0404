# -*- coding: utf-8 -*-
"""Capstone Project_ - Problem for Covid - 19 Data Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M-4R-VgJ8mINdi3rF4S3ItbeIfi8nj-U

#     Covid Analysis_Capstone_Project
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

"""## 1. Import the dataset using Pandas from above mentioned url."""

df = pd.read_csv("https://raw.githubusercontent.com/SR1608/Datasets/main/covid-data.csv", sep =",")

df.head()

df.tail()

df

"""## 2. High Level Data Understanding:

### A). Find no. of rows & columns in the dataset
"""

df.shape

"""As we can see there are 57394 rows and 49 columns

### b). Data types of columns.
"""

df.dtypes

"""These four column "iso_code', 'continent', 'location', 'date'" are Object.

Rest of all the columns are float64

### C). Info & describe of data in dataframe.
"""

df.info()

"""It provids the information of the dataset including columns names, observation filled count, data types.

**Observation - As all columns have not equal count of Non-Null values. So there are some missing values.**
"""

pd.set_option('display.max_columns', None)
df.describe(include="all").round(2)

"""As per Min, 25% , 50%(Median),75% and Max - We can see that there are some outliers in the dataset.

## 3). Low Level Data Understanding :

### a). Find count of unique values in location column
"""

df['location'].nunique()

"""### b). Find which continent has maximum frequency using values counts."""

df['continent'].value_counts()

"""#### Observation:- Europe has maximum frequency of covid cases.

### c). Find maximum & mean value in 'total_cases'
"""

df['total_cases'].max()

df['total_cases'].mean()

df['total_cases'].min()

"""### d). Find 25%,50% & 75% quartile value in 'total_deaths'"""

#df['total_deaths'].quantile(np.arange(.25,1,.25))
df['total_deaths'].describe().round(2)

"""### e). Find which continent has maximum 'human_development_index'."""

df.groupby("continent").agg({"human_development_index":"max"}).head(1)

"""****Observation - Africa has Maximum Human Development Index then other continents**

### f). Find which continent has minimum 'gdp_per_capita'.
"""

df.groupby('continent').agg({'gdp_per_capita':'min'}).head(1)

"""**Observation - Africa has minimum GDP per capita then other continents**

## 4). Filter the dataframe with only this columns: ['continent','location','date','total_cases','total_deaths','gdp_per_capita','human_development_index'] and update the data frame.
"""

df=df[['continent','location','date','total_cases','total_deaths','gdp_per_capita','human_development_index']]
df

df

"""## 5). Data Cleaning

### a). Remove all duplicates observations
"""

df.duplicated().sum()

df.drop_duplicates()

"""### b). Find missing values in all columns"""

df.isnull().sum()

"""### c). Remove all observations where continent column value is missing"""

df.dropna(subset=["continent"])

"""### d).  Fill all missing values with 0"""

df= df.fillna(0)

df.isnull().sum()

"""## 6). Date time format :

### a). Convert date column in datetime format using pandas.to_datetime
"""

df['date']= pd.to_datetime(df['date'])

df.dtypes

"""### b). Create new column month after extracting month data from date column"""

df['month'] = pd.DatetimeIndex(df['date']).month

df

"""## 7). Data Aggregation:

### a). Find max value in all columns using groupby function on 'continent' column
"""

df.groupby('continent').max().reset_index()

"""### b). Store the result in a new dataframe named 'df_groupby'. (Use df_groupby dataframe for all further analysis)

"""

df_groupby = df.groupby('continent').max().reset_index()
df_groupby

"""## 8).  Feature Engineering :

### a). Create a new feature 'total_deaths_to_total_cases' by ratio of  'total_deaths' column to 'total_cases'
"""

df_groupby["total_deaths_to_total_cases"]=df_groupby["total_deaths"]/df_groupby["total_cases"]

df_groupby["total_deaths_to_total_cases"]*100

df_groupby

"""## 9). Data Visualization :

### a). Perform Univariate analysis on 'gdp_per_capita' column by plotting histogram using seaborn dist plot.
"""

sns.distplot(df["gdp_per_capita"])

"""### b). Plot a scatter plot of 'total_cases' & 'gdp_per_capita'"""

sns.jointplot(data=df_groupby,x="total_cases",y="gdp_per_capita",kind="scatter")

"""### c). Plot Pairplot on df_groupby dataset."""

sns.pairplot(data=df_groupby)

"""### d). Plot a bar plot of 'continent' column with 'total_cases' . Tip : using kind='bar' in seaborn catplot"""

sns.catplot(data=df_groupby,x="continent",y="total_cases",kind="bar")

"""## 10). Save the df_groupby dataframe in your local drive using pandas.to_csv function ."""

df.to_csv("covid_Data.csv")

