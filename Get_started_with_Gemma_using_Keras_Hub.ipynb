{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "Get started with Gemma using Keras Hub"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceType": "modelInstanceVersion",
          "sourceId": 10260,
          "databundleVersionId": 7715865,
          "modelInstanceId": 5171
        },
        {
          "sourceType": "modelInstanceVersion",
          "sourceId": 11371,
          "databundleVersionId": 7771674,
          "modelInstanceId": 5171
        }
      ],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "papermill": {
      "default_parameters": {},
      "duration": 895.907459,
      "end_time": "2024-02-21T09:35:28.067368",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-02-21T09:20:32.159909",
      "version": "2.5.0"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "zGXer7YnHuba"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "keras_gemma_keras_gemma_2b_en_1_path = kagglehub.model_download('keras/gemma/Keras/gemma_2b_en/1')\n",
        "keras_gemma_keras_gemma_2b_en_2_path = kagglehub.model_download('keras/gemma/Keras/gemma_2b_en/2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "XX9TT_nAHubh",
        "outputId": "42499cba-045a-4108-fafc-baf050342963"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "KaggleApiHTTPError",
          "evalue": "403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/keras/gemma/Keras/gemma_2b_en/1. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://www.kaggle.com/api/v1/models/keras/gemma/Keras/gemma_2b_en/1/files?page_size=25",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2a253024af38>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# NOTEBOOK.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mkeras_gemma_keras_gemma_2b_en_1_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras/gemma/Keras/gemma_2b_en/1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mkeras_gemma_keras_gemma_2b_en_2_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras/gemma/Keras/gemma_2b_en/2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/models.py\u001b[0m in \u001b[0;36mmodel_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_model_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Model: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/resolver.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, handle, path, force_download)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mSome\u001b[0m \u001b[0mcases\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCompetition\u001b[0m \u001b[0mdatasource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbased\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Note handles are immutable, so _resolve() could not have altered our reference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_resolve\u001b[0;34m(self, h, path, force_download)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# - <= 25 files: Download files in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;31m# > 25 files: Download the archive and uncompress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_more\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_more\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# Downloading the full archived bundle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/http_resolver.py\u001b[0m in \u001b[0;36m_list_files\u001b[0;34m(api_client, h)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_list_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_client\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKaggleApiV1Client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelHandle\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     \u001b[0mjson_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_build_list_model_instance_version_files_url_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"files\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Invalid ListModelInstanceVersionFiles API response. Expected to include a 'files' field\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, path, resource_handle)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEFAULT_CONNECT_TIMEOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEFAULT_READ_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         ) as response:\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mkaggle_api_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_for_version_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/kagglehub/exceptions.py\u001b[0m in \u001b[0;36mkaggle_api_raise_for_status\u001b[0;34m(response, resource_handle)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# Default handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKaggleApiHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKaggleApiHTTPError\u001b[0m: 403 Client Error.\n\nYou don't have permission to access resource at URL: https://www.kaggle.com/models/keras/gemma/Keras/gemma_2b_en/1. The server reported the following issues: Permission denied on resource (or it may not exists).\nPlease make sure you are authenticated if you are trying to access a private resource or a resource requiring consent."
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2024 Google LLC."
      ],
      "metadata": {
        "id": "4qxv4Sn9b8CE",
        "papermill": {
          "duration": 0.008955,
          "end_time": "2024-02-21T09:20:35.709303",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.700348",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:03:35.914465Z",
          "iopub.execute_input": "2025-02-05T20:03:35.914759Z",
          "iopub.status.idle": "2025-02-05T20:03:35.91826Z",
          "shell.execute_reply.started": "2025-02-05T20:03:35.914737Z",
          "shell.execute_reply": "2025-02-05T20:03:35.917442Z"
        },
        "papermill": {
          "duration": 0.018757,
          "end_time": "2024-02-21T09:20:35.736697",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.71794",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "pNmf47oWHubl"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/get_started\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  </td>\n",
        "    <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/get_started.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335\"><img src=\"https://ai.google.dev/images/cloud-icon.svg\" width=\"40\" />Open in Vertex AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/keras-team/keras-hub/tree/master/keras_hub/src/models/gemma\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.007768,
          "end_time": "2024-02-21T09:20:35.752652",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.744884",
          "status": "completed"
        },
        "tags": [],
        "id": "51tGcQ-0Hubn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get started with Gemma using Keras Hub\n",
        "\n",
        "This tutorial shows you how to get started with Gemma using [Keras Hub](https://keras.io/keras_hub/). Gemma is a family of lightweight, state-of-the art open models built from the same research and technology used to create the Gemini models. Keras Hub is a collection of many models implemented in [Keras](https://keras.io/) and runnable on JAX, PyTorch, and TensorFlow.\n",
        "\n",
        "In this tutorial, you'll use Gemma to generate text responses to several prompts. If you're new to Keras, you might want to read [Getting started with Keras](https://keras.io/getting_started/) before you begin, but you don't have to. You'll learn more about Keras as you work through this tutorial."
      ],
      "metadata": {
        "id": "PXNm5_p_oxMF",
        "papermill": {
          "duration": 0.008272,
          "end_time": "2024-02-21T09:20:35.769189",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.760917",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "mERVCCsGUPIJ",
        "papermill": {
          "duration": 0.008938,
          "end_time": "2024-02-21T09:20:35.786574",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.777636",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gemma setup\n",
        "\n",
        "To complete this tutorial, you will first need to complete the setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). The Gemma setup instructions show you how to do the following:\n",
        "\n",
        "Gemma models are hosted by Kaggle. To use Gemma, request access on Kaggle:\n",
        "\n",
        "- Sign in or register at [kaggle.com](https://www.kaggle.com)\n",
        "- Open the [Gemma model card](https://www.kaggle.com/models/google/gemma) and select _\"Request Access\"_\n",
        "- Complete the consent form and accept the terms and conditions\n"
      ],
      "metadata": {
        "id": "QQ6W7NzRe1VM",
        "papermill": {
          "duration": 0.008812,
          "end_time": "2024-02-21T09:20:35.804737",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.795925",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install dependencies\n",
        "\n",
        "Install Keras and Keras Hub"
      ],
      "metadata": {
        "id": "z9oy3QUmXtSd",
        "papermill": {
          "duration": 0.008324,
          "end_time": "2024-02-21T09:20:35.821692",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.813368",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
        "!pip install -q -U keras-hub\n",
        "!pip install  -q -U keras"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:07:01.929198Z",
          "iopub.execute_input": "2025-02-05T20:07:01.929537Z",
          "iopub.status.idle": "2025-02-05T20:07:08.908537Z",
          "shell.execute_reply.started": "2025-02-05T20:07:01.929509Z",
          "shell.execute_reply": "2025-02-05T20:07:08.907289Z"
        },
        "id": "UcGLzDeQ8NwN",
        "papermill": {
          "duration": 39.321226,
          "end_time": "2024-02-21T09:21:15.151995",
          "exception": false,
          "start_time": "2024-02-21T09:20:35.830769",
          "status": "completed"
        },
        "tags": [],
        "_kg_hide-output": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import packages\n",
        "\n",
        "Import Keras and Keras Hub."
      ],
      "metadata": {
        "id": "FX47AUYrXwLK",
        "papermill": {
          "duration": 0.008053,
          "end_time": "2024-02-21T09:21:15.168461",
          "exception": false,
          "start_time": "2024-02-21T09:21:15.160408",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_hub\n",
        "import numpy as np"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:03:55.695945Z",
          "iopub.execute_input": "2025-02-05T20:03:55.69623Z",
          "iopub.status.idle": "2025-02-05T20:04:08.945906Z",
          "shell.execute_reply.started": "2025-02-05T20:03:55.696209Z",
          "shell.execute_reply": "2025-02-05T20:04:08.944953Z"
        },
        "id": "ww83zI9ToPso",
        "papermill": {
          "duration": 20.44507,
          "end_time": "2024-02-21T09:21:35.62369",
          "exception": false,
          "start_time": "2024-02-21T09:21:15.17862",
          "status": "completed"
        },
        "tags": [],
        "_kg_hide-output": true,
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select a backend\n",
        "\n",
        "Keras is a high-level, multi-framework deep learning API designed for simplicity and ease of use. [Keras 3](https://keras.io/keras_3) lets you choose the backend: TensorFlow, JAX, or PyTorch. All three will work for this tutorial."
      ],
      "metadata": {
        "id": "Pm5cVOFt5YvZ",
        "papermill": {
          "duration": 0.012975,
          "end_time": "2024-02-21T09:21:35.649131",
          "exception": false,
          "start_time": "2024-02-21T09:21:35.636156",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"tensorflow\" or \"torch\"."
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:04:08.94705Z",
          "iopub.execute_input": "2025-02-05T20:04:08.947671Z",
          "iopub.status.idle": "2025-02-05T20:04:08.951357Z",
          "shell.execute_reply.started": "2025-02-05T20:04:08.947629Z",
          "shell.execute_reply": "2025-02-05T20:04:08.950512Z"
        },
        "id": "7rS7ryTs5wjf",
        "papermill": {
          "duration": 0.020559,
          "end_time": "2024-02-21T09:21:35.678502",
          "exception": false,
          "start_time": "2024-02-21T09:21:35.657943",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a model\n",
        "\n",
        "Keras Hub provides implementations of many popular [model architectures](https://keras.io/api/keras_nlp/models/). In this tutorial, you'll create a model using `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n",
        "\n",
        "Create the model using the `from_preset` method:"
      ],
      "metadata": {
        "id": "ZsxDCbLN555T",
        "papermill": {
          "duration": 0.008721,
          "end_time": "2024-02-21T09:21:35.698183",
          "exception": false,
          "start_time": "2024-02-21T09:21:35.689462",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm = keras_hub.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:04:15.735647Z",
          "iopub.execute_input": "2025-02-05T20:04:15.735957Z",
          "iopub.status.idle": "2025-02-05T20:05:23.117522Z",
          "shell.execute_reply.started": "2025-02-05T20:04:15.735935Z",
          "shell.execute_reply": "2025-02-05T20:05:23.116828Z"
        },
        "id": "yygIK9DEIldp",
        "papermill": {
          "duration": 113.918294,
          "end_time": "2024-02-21T09:23:29.630183",
          "exception": false,
          "start_time": "2024-02-21T09:21:35.711889",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "`from_preset` instantiates the model from a preset architecture and weights. In the code above, the string `\"gemma_2b_en\"` specifies the preset architecture: a Gemma model with 2 billion parameters. (A Gemma model with 7 billion parameters is also available. To run the larger model in Colab, you need access to the premium GPUs available in paid plans. Alternatively, you can perform [distributed tuning on a Gemma 7B model](https://ai.google.dev/gemma/docs/distributed_tuning) on Kaggle or Google Cloud.)\n",
        "\n",
        "Use `summary` to get more info about the model:"
      ],
      "metadata": {
        "id": "XrAWvsU6pI0E",
        "papermill": {
          "duration": 0.009095,
          "end_time": "2024-02-21T09:23:29.648821",
          "exception": false,
          "start_time": "2024-02-21T09:23:29.639726",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:05:27.792595Z",
          "iopub.execute_input": "2025-02-05T20:05:27.792944Z",
          "iopub.status.idle": "2025-02-05T20:05:27.81892Z",
          "shell.execute_reply.started": "2025-02-05T20:05:27.792915Z",
          "shell.execute_reply": "2025-02-05T20:05:27.818219Z"
        },
        "id": "e5nEbTdApL7W",
        "papermill": {
          "duration": 0.067494,
          "end_time": "2024-02-21T09:23:29.72571",
          "exception": false,
          "start_time": "2024-02-21T09:23:29.658216",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see from the summary, the model has 2.5 billion trainable parameters."
      ],
      "metadata": {
        "id": "81KHdRYOrWYm",
        "papermill": {
          "duration": 0.010233,
          "end_time": "2024-02-21T09:23:29.749578",
          "exception": false,
          "start_time": "2024-02-21T09:23:29.739345",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate text\n",
        "\n",
        "Now it's time to generate some text! The model has a `generate` method that generates text based on a prompt. The optional `max_length` argument specifies the maximum length of the generated sequence.\n",
        "\n",
        "Try it out with the prompt `\"What is the meaning of life?\"`."
      ],
      "metadata": {
        "id": "FOBW7piN5-sl",
        "papermill": {
          "duration": 0.010186,
          "end_time": "2024-02-21T09:23:29.771881",
          "exception": false,
          "start_time": "2024-02-21T09:23:29.761695",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.generate(\"What is the meaning of life?\", max_length=64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:05:33.962745Z",
          "iopub.execute_input": "2025-02-05T20:05:33.963035Z",
          "iopub.status.idle": "2025-02-05T20:05:51.51617Z",
          "shell.execute_reply.started": "2025-02-05T20:05:33.963015Z",
          "shell.execute_reply": "2025-02-05T20:05:51.515301Z"
        },
        "id": "aae5GHrdpj2_",
        "papermill": {
          "duration": 153.317812,
          "end_time": "2024-02-21T09:26:03.102408",
          "exception": false,
          "start_time": "2024-02-21T09:23:29.784596",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try calling `generate` again with a different prompt."
      ],
      "metadata": {
        "id": "qH0eFH_DvYwM",
        "papermill": {
          "duration": 0.011582,
          "end_time": "2024-02-21T09:26:03.125363",
          "exception": false,
          "start_time": "2024-02-21T09:26:03.113781",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.generate(\"How does the brain work?\", max_length=64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:05:59.256967Z",
          "iopub.execute_input": "2025-02-05T20:05:59.257261Z",
          "iopub.status.idle": "2025-02-05T20:06:00.571229Z",
          "shell.execute_reply.started": "2025-02-05T20:05:59.257238Z",
          "shell.execute_reply": "2025-02-05T20:06:00.570397Z"
        },
        "id": "VEyTnnNGvgGG",
        "papermill": {
          "duration": 124.920909,
          "end_time": "2024-02-21T09:28:08.056821",
          "exception": false,
          "start_time": "2024-02-21T09:26:03.135912",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you're running on JAX or TensorFlow backends, you'll notice that the second `generate` call returns nearly instantly. This is because each call to `generate` for a given batch size and `max_length` is compiled with XLA. The first run is expensive, but subsequent runs are much faster."
      ],
      "metadata": {
        "id": "vVlCnY7Gvm7U",
        "papermill": {
          "duration": 0.01103,
          "end_time": "2024-02-21T09:28:08.078435",
          "exception": false,
          "start_time": "2024-02-21T09:28:08.067405",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also provide batched prompts using a list as input:"
      ],
      "metadata": {
        "id": "mw5XkiHU11Ft",
        "papermill": {
          "duration": 0.010923,
          "end_time": "2024-02-21T09:28:08.101562",
          "exception": false,
          "start_time": "2024-02-21T09:28:08.090639",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.generate(\n",
        "    [\"What is the meaning of life?\",\n",
        "     \"How does the brain work?\"],\n",
        "    max_length=64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:06:05.745275Z",
          "iopub.execute_input": "2025-02-05T20:06:05.745683Z",
          "iopub.status.idle": "2025-02-05T20:06:22.425519Z",
          "shell.execute_reply.started": "2025-02-05T20:06:05.745652Z",
          "shell.execute_reply": "2025-02-05T20:06:22.424582Z"
        },
        "id": "xV6vs8_C2BGt",
        "papermill": {
          "duration": 284.668615,
          "end_time": "2024-02-21T09:32:52.781544",
          "exception": false,
          "start_time": "2024-02-21T09:28:08.112929",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional: Try a different sampler\n",
        "\n",
        "You can control the generation strategy for `GemmaCausalLM` by setting the `sampler` argument on `compile()`. By default, [`\"greedy\"`](https://keras.io/api/keras_nlp/samplers/greedy_sampler/#greedysampler-class) sampling will be used.\n",
        "\n",
        "As an experiment, try setting a [`\"top_k\"`](https://keras.io/api/keras_nlp/samplers/top_k_sampler/) strategy:"
      ],
      "metadata": {
        "id": "MaVWoSpo3XyY",
        "papermill": {
          "duration": 0.012673,
          "end_time": "2024-02-21T09:32:52.817322",
          "exception": false,
          "start_time": "2024-02-21T09:32:52.804649",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.compile(sampler=\"top_k\")\n",
        "gemma_lm.generate(\"What is the meaning of life?\", max_length=64)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-02-05T20:06:25.765939Z",
          "iopub.execute_input": "2025-02-05T20:06:25.766265Z",
          "iopub.status.idle": "2025-02-05T20:06:42.008973Z",
          "shell.execute_reply.started": "2025-02-05T20:06:25.766239Z",
          "shell.execute_reply": "2025-02-05T20:06:42.008166Z"
        },
        "id": "mx55VQpN4DAK",
        "papermill": {
          "duration": 151.788202,
          "end_time": "2024-02-21T09:35:24.618187",
          "exception": false,
          "start_time": "2024-02-21T09:32:52.829985",
          "status": "completed"
        },
        "tags": [],
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the default greedy algorithm always picks the token with the largest probability, the top-K algorithm randomly picks the next token from the tokens of top K probability.\n",
        "\n",
        "You don't have to specify a sampler, and you can ignore the last code snippet if it's not helpful to your use case. If you'd like learn more about the available samplers, see [Samplers](https://keras.io/api/keras_nlp/samplers/)."
      ],
      "metadata": {
        "id": "-okKgK4LfO0f",
        "papermill": {
          "duration": 0.010755,
          "end_time": "2024-02-21T09:35:24.640256",
          "exception": false,
          "start_time": "2024-02-21T09:35:24.629501",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What's next\n",
        "\n",
        "In this tutorial, you learned how to generate text using Keras Hub and Gemma. Here are a few suggestions for what to learn next:\n",
        "\n",
        "* Learn how to [finetune a Gemma model](https://ai.google.dev/gemma/docs/lora_tuning).\n",
        "* Learn how to perform [distributed fine-tuning and inference on a Gemma model](https://ai.google.dev/gemma/docs/distributed_tuning).\n",
        "* Learn how to [use Gemma models with Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/open-models/use-gemma)."
      ],
      "metadata": {
        "id": "jBrbTYasoo-J",
        "papermill": {
          "duration": 0.010532,
          "end_time": "2024-02-21T09:35:24.661797",
          "exception": false,
          "start_time": "2024-02-21T09:35:24.651265",
          "status": "completed"
        },
        "tags": []
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "r0_m-lPRHubz"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}